{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Dask on AzureML\n",
    "\n",
    "This notebook shows how to run a Dask cluster on an AzureML Compute cluster. \n",
    "For setup instructions of you python environment, please see the [Readme](./README.md)\n",
    "\n",
    "Once the Compute Cluster get started runs regardless of usage of the Compute Cluster, you'll see the cluster in 'running' status. So if you don't have job to run or not using it, please cancel Run to stop the cluster. In other words, as you run the cluster a bit manually, stop the cluster by manual (or SDK)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from azureml.core import Workspace, Experiment, Environment, Datastore, Dataset, ScriptRunConfig\n",
    "from azureml.core.runconfig import PyTorchConfiguration\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to Azure Machine Learning Service\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create AML Compute Cluster \n",
    "\n",
    "As you need to connect to compute cluster via Compute Instance, make sure you create __SSH enabled__ AML Compute Cluster. And of course remember the ID and private key to do forport-forwarding from your local host (PC/MAC) to Dask Scheduler.\n",
    "\n",
    "You need to update __USERNAME__, __ADMINUSERSSHKEY__, __VNETRGNAME__, __VNETNAME__ and __SUBNETNAME__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"dask-inter-cpu-1\"\n",
    "VMSIZE='STANDARD_DS3_V2'\n",
    "USERNAME=''\n",
    "ADMINUSERSSHKEY = ''\n",
    "MAXNODE=2\n",
    "VNETRGNAME=''\n",
    "VNETNAME=''\n",
    "SUBNETNAME=''\n",
    "\n",
    "\n",
    "if USERNAME != '' or ADMINUSERSSHKEY !='':\n",
    "    # Verify that cluster does not exist already\n",
    "    try:\n",
    "        dask_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "        print('Found existing cluster, use it.')\n",
    "    except ComputeTargetException:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size=VMSIZE,\n",
    "                                                            min_nodes=0, max_nodes=MAXNODE,\n",
    "                                                            remote_login_port_public_access='Enabled',\n",
    "                                                            admin_username=USERNAME, \n",
    "                                                            admin_user_ssh_key=ADMINUSERSSHKEY,\n",
    "                                                            vnet_resourcegroup_name=VNETRGNAME,\n",
    "                                                            vnet_name=VNETNAME,\n",
    "                                                            subnet_name=SUBNETNAME)\n",
    "        dask_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "    dask_cluster.wait_for_completion(show_output=True)\n",
    "else:\n",
    "    print('Check your user name and password')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daskEnv = Environment.from_conda_specification('interactieDask', './conda.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register sample storage account for demo.\n",
    "\n",
    "![datastore](https://raw.githubusercontent.com/hyssh/aml-dask-interactive/main/img/datastore_folder_files.png)\n",
    "\n",
    "If you want to use your contain in a storage account, please update following account name and sas_token accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore_name = 'mtcseattle'\n",
    "container_name = 'azure-service-classifier'\n",
    "account_name = 'mtcseattle'\n",
    "sas_token = '?sv=2020-04-08&st=2021-05-26T04%3A39%3A46Z&se=2022-05-27T04%3A39%3A00Z&sr=c&sp=rl&sig=CTFMEu24bo2X06G%2B%2F2aKiiPZBzvlWHELe15rNFqULUk%3D'\n",
    "\n",
    "datastore = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                                    datastore_name=datastore_name, \n",
    "                                                    container_name=container_name,\n",
    "                                                    account_name=account_name, \n",
    "                                                    sas_token=sas_token,\n",
    "                                                    overwrite=True)\n",
    "datastore = Datastore.get(ws, 'mtcseattle')\n",
    "\n",
    "inputDataset = Dataset.File.from_files(path=(datastore, 'data'))\n",
    "\n",
    "# This is optional \n",
    "# inputDataset = inputDataset.register(workspace=ws,\n",
    "#                                        name='Azure Services Dataset',\n",
    "#                                        description='Dataset containing azure related posts on Stackoverflow',\n",
    "#                                        create_new_version=True)\n",
    "\n",
    "# inputDataset = Dataset.get_by_name(ws, 'Azure Services Dataset')\n",
    "# inputDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set ScriptRunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "src = ScriptRunConfig(source_directory='./source',\n",
    "                       script='startDask.py',\n",
    "                       arguments=[inputDataset.as_mount(path_on_compute='data')],\n",
    "                       environment=daskEnv,\n",
    "                       compute_target=dask_cluster,\n",
    "                       distributed_job_config=PyTorchConfiguration(node_count=MAXNODE)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the ScriptRunConfig in a Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expName = 'Interactive Dask Cluster'\n",
    "run = Experiment(ws, expName).submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get private IP address of headnode.\n",
    "\n",
    "The reason why we need the private IP address of headnode is to use it to look up public ip of the head node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "mlflow.set_experiment(expName)\n",
    "mlflowrun = mlflow.get_run(run.id)\n",
    "\n",
    "print(\"waiting for scheduler node's ip\")\n",
    "while not 'headnode' in mlflowrun._data.params:\n",
    "    print('.', end =\"\")\n",
    "    time.sleep(5)\n",
    "\n",
    "clear_output()\n",
    "headnode_private_ip = mlflowrun._data.params['headnode']\n",
    "print('Headnode has IP:', headnode_private_ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the private IP address to find Public IP addres of the head node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's find the public IP and ssh port of the head node\n",
    "headnode_public_ip = None\n",
    "headnode_ssh_port = None\n",
    "for node in dask_cluster.list_nodes():\n",
    "    if node['privateIpAddress'] == headnode_private_ip:\n",
    "        headnode_public_ip = node['publicIpAddress']\n",
    "        headnode_ssh_port = node['port']\n",
    "        break\n",
    "        \n",
    "if headnode_public_ip == None:\n",
    "    print('Headnode not found in cluster')\n",
    "else:\n",
    "    print(f'Headnode is at {headnode_public_ip}:{headnode_ssh_port}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish the port-forwarding from your localhost to Dask Scheduler\n",
    "\n",
    "You need to build an SSH port forwarder through SSH login from your laptop to Compute Cluster.\n",
    "\n",
    "In the prior cell we looked up the public IP and port of the headnode of the cluster \n",
    "\n",
    "Now, open the terminal on your laptop and type what the following cell outputs  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ssh {USERNAME}@{headnode_public_ip} -p {headnode_ssh_port} -L 8786:localhost:8786 -L 8788:{headnode_private_ip}:8787 -L 9999:localhost:8888')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to leave the terminal tab open to keep the port-forward running\n",
    "\n",
    "![ssh](https://raw.githubusercontent.com/hyssh/aml-dask-interactive/main/img/port-forwarding.png)\n",
    "\n",
    "As you see, you are forwarding 3 ports \n",
    "\n",
    "1. __8786__ is for the scheduler and will be used to connect the client to the cluster\n",
    "2. __8788__ is for the Bokeh app that shows the activity on the cluster (we are mapping to the local port 8788 to avoid a conflict with the RStudio Server running on the Compute Instance)\n",
    "3. __9999__ is for a jupyter instance running on the head node. You can connect to the scheduler from the jupyter running on your Notebook VM or from this jupyter instance on the head node.   \n",
    "\n",
    "To access the Notebook that running on Dask, use localhost and add port `:9999` with token. \n",
    "To access the Bokeh app, use localhost and add port `:8788`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"waiting for jupyter token\")\n",
    "while not 'jupyter-token' in mlflowrun._data.params:\n",
    "    print('.', end =\"\")\n",
    "    time.sleep(5)\n",
    "\n",
    "clear_output()\n",
    "jupyterToken = mlflowrun._data.params['jupyter-token']\n",
    "print('Copy following url to access to Dask cluster notebook:')\n",
    "print(f'http://localhost:9999/notebooks?token={jupyterToken}')\n",
    "print('Copy following url to access to Dask cluster Bokeh:')\n",
    "print(f'http://localhost:8788')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, you are seeing this after you clicked on the Bokeh link and then select 'Status':\n",
    "\n",
    "![Bokeh](https://raw.githubusercontent.com/hyssh/aml-dask-interactive/main//img/bokeh.png)\n",
    "\n",
    "If you are wondering what all this port business in accomplishing, please see the graph below that tries to illustrate who talks to whom and how.\n",
    "\n",
    "![arch_dask](https://raw.githubusercontent.com/hyssh/aml-dask-interactive/main/img/architecture_dask.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run some jobs on the cluster\n",
    "If you are able to see the Bokeh app, it is time to access to Notebook running on Dask cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Dask jobs\n",
    "\n",
    "If you access to the notebook running on Dask, now it's time to run some sample.\n",
    "\n",
    "Pleas try to Use __Dask_sample.ipynb__ to run some dask jobs.\n",
    "\n",
    "You need to download the sample to the compute cluster running Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shut cluster down\n",
    "To shut the cluster down, cancel the job that runs the cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in ws.experiments[expName].get_runs():\n",
    "    if run.get_status() == \"Running\":\n",
    "        print(f'cancelling run {run.id}')\n",
    "        run.cancel()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6865bf3d0c8cd76df395d5f2226878eaf83cb8580fb53dcdaa2bb9522d89ec7"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
